{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline, text-based similarity and retrieval, simple UI, accuracy metrics\n",
    "\n",
    "- Input (query) to the IR system is the title and artist of a song (track) from the dataset\n",
    "\n",
    "- Output of the IR system is a list of songs from the dataset (title and artist) of length N that\n",
    "are similar to the query song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast  \n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hashlib, os, json\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import Combobox, Button, VBox, Output\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline System\n",
    "\n",
    "Create a simple baseline system that randomly (regardless of the query) selects N items\n",
    "from the catalog (excluding the query item); Make sure that the system produces new\n",
    "results for each query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01rMxQv6vhyE1oQX</td>\n",
       "      <td>[rock, pop punk]</td>\n",
       "      <td>Against the Current</td>\n",
       "      <td>Chasing Ghosts</td>\n",
       "      <td>In Our Bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02ZnlCGZEbkfCDxo</td>\n",
       "      <td>[pop, italian pop, latin, europop, ambient, po...</td>\n",
       "      <td>Laura Pausini</td>\n",
       "      <td>Tra Te E Il Mare</td>\n",
       "      <td>The Best of Laura Pausini - E Ritorno Da Te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04OjszRi9rC5BlHC</td>\n",
       "      <td>[experimental, folk, lo fi, freak folk, indie ...</td>\n",
       "      <td>Grizzly Bear</td>\n",
       "      <td>Knife</td>\n",
       "      <td>Yellow House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04iitW3ffa0mhpx3</td>\n",
       "      <td>[pop, r b, hip hop, soul, rhythm and blues, si...</td>\n",
       "      <td>Ne-Yo</td>\n",
       "      <td>Miss Independent</td>\n",
       "      <td>Year Of The Gentleman (Bonus Track Edition)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04xUDjAYC14jsHyH</td>\n",
       "      <td>[punk, emo, post hardcore, post punk, melodic ...</td>\n",
       "      <td>Jawbreaker</td>\n",
       "      <td>Jinx Removing</td>\n",
       "      <td>24 Hour Revenge Therapy (Remastered)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              genre  \\\n",
       "0  01rMxQv6vhyE1oQX                                   [rock, pop punk]   \n",
       "1  02ZnlCGZEbkfCDxo  [pop, italian pop, latin, europop, ambient, po...   \n",
       "2  04OjszRi9rC5BlHC  [experimental, folk, lo fi, freak folk, indie ...   \n",
       "3  04iitW3ffa0mhpx3  [pop, r b, hip hop, soul, rhythm and blues, si...   \n",
       "4  04xUDjAYC14jsHyH  [punk, emo, post hardcore, post punk, melodic ...   \n",
       "\n",
       "                artist              song  \\\n",
       "0  Against the Current    Chasing Ghosts   \n",
       "1        Laura Pausini  Tra Te E Il Mare   \n",
       "2         Grizzly Bear             Knife   \n",
       "3                Ne-Yo  Miss Independent   \n",
       "4           Jawbreaker     Jinx Removing   \n",
       "\n",
       "                                    album_name  \n",
       "0                                 In Our Bones  \n",
       "1  The Best of Laura Pausini - E Ritorno Da Te  \n",
       "2                                 Yellow House  \n",
       "3  Year Of The Gentleman (Bonus Track Edition)  \n",
       "4         24 Hour Revenge Therapy (Remastered)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process datasets \n",
    "def load_dataset_with_info(genre_file, info_file):\n",
    "    \"\"\"\n",
    "    Load the genre, metadata, and information datasets.\n",
    "    Merge them into one and parse the 'genre' column.\n",
    "    \"\"\"\n",
    "    # Load genres and information\n",
    "    genres = pd.read_csv(genre_file, sep='\\t')\n",
    "    info = pd.read_csv(info_file, sep='\\t')\n",
    "    \n",
    "    # Ensure column names are consistent\n",
    "    genres.columns = genres.columns.str.strip()\n",
    "    info.columns = info.columns.str.strip()\n",
    "    \n",
    "    # Parse 'genre' column into lists\n",
    "    genres['genre'] = genres['genre'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Merge all datasets on the 'id' column\n",
    "    dataset = pd.merge(genres, info, on='id')\n",
    "    return dataset\n",
    "\n",
    "# Define file paths\n",
    "genre_file = \"dataset/id_genres_mmsr.tsv\"\n",
    "info_file = \"dataset/id_information_mmsr.tsv\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset_with_info(genre_file, info_file)\n",
    "\n",
    "# Display a sample to ensure data is loaded correctly\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Song: Chasing Ghosts by Against the Current\n",
      "\n",
      "Random Output (Song and Artist):\n",
      "                                    song                     artist\n",
      "251                      Endless Endings  The Dillinger Escape Plan\n",
      "2366  Save Yourself, I'll Hold Them Back        My Chemical Romance\n",
      "2907            Too Much Of A Good Thing                   The Sons\n",
      "3759                           Pensacola       Manchester Orchestra\n",
      "1453                   Me In My Own Head                  Beartooth\n",
      "3252                    One In A Million              Pet Shop Boys\n",
      "4755                               Crawl                Chris Brown\n",
      "846             That's Just What You Are                 Aimee Mann\n",
      "7            The Devil Is in the Details           Boards of Canada\n",
      "2679                             Que Lio               Willie Colón\n"
     ]
    }
   ],
   "source": [
    "# Random Baseline System (Adjusted for Song and Artist)\n",
    "def random_baseline(query_song, dataset, N=10):\n",
    "    \"\"\"\n",
    "    Generate a random list of N songs excluding the query song.\n",
    "    Internally keep 'id', but exclude it in the output display.\n",
    "    \"\"\"\n",
    "    filtered_dataset = dataset[dataset['id'] != query_song['id']].sample(frac=1, random_state=random.randint(0, 10000))\n",
    "    return filtered_dataset.head(N)\n",
    "\n",
    "\n",
    "# Test the adjusted random baseline\n",
    "query_song = dataset.iloc[0]  # Example query song\n",
    "print(\"Query Song:\", query_song['song'], \"by\", query_song['artist'])\n",
    "\n",
    "random_output = random_baseline(query_song, dataset, N=10)\n",
    "print(\"\\nRandom Output (Song and Artist):\")\n",
    "print(random_output[['song', 'artist']])  # Display only song and artist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Metrics\n",
    "\n",
    "Implement and compute accuracy metrics for your baseline (Precision@10, Recall@10,\n",
    "NDCG@10, MRR), averaged over all queries; Use genre as relevance criterion (i.e., a\n",
    "retrieved song is considered relevant if its top genre matches the top genre of the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision@K\n",
    "def precision_at_k(retrieved, relevant, k=10):\n",
    "    retrieved_relevant = [song for song in retrieved[:k] if song in relevant]\n",
    "    return len(retrieved_relevant) / k\n",
    "\n",
    "# Compute Recall@K\n",
    "def recall_at_k(retrieved, relevant, k=10):\n",
    "    retrieved_relevant = [song for song in retrieved[:k] if song in relevant]\n",
    "    return len(retrieved_relevant) / len(relevant) if relevant else 0\n",
    "\n",
    "# Compute Mean Reciprocal Rank (MRR)\n",
    "def mean_reciprocal_rank(retrieved, relevant):\n",
    "    for idx, song in enumerate(retrieved):\n",
    "        if song in relevant:\n",
    "            return 1 / (idx + 1)\n",
    "    return 0\n",
    "\n",
    "# Compute NDCG@K\n",
    "def ndcg_at_k(retrieved, relevant, k=10):\n",
    "    y_true = [1 if song in relevant else 0 for song in retrieved[:k]]\n",
    "    y_score = [1] * len(y_true)  # Assume all retrieved items have the same score\n",
    "    return ndcg_score([y_true], [y_score], k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Random Baseline System:\n",
      "Precision@10: 0.1693\n",
      "Recall@10: 0.0018\n",
      "NDCG@10: 0.3595\n",
      "MRR: 0.2938\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Baseline System\n",
    "def evaluate_baseline_with_info(dataset, N=10):\n",
    "    \"\"\"\n",
    "    Evaluate the random baseline system on all queries.\n",
    "    Only show 'song' and 'artist' in the output, but use 'id' for evaluations.\n",
    "    \"\"\"\n",
    "    precision_list, recall_list, ndcg_list, mrr_list = [], [], [], []\n",
    "    for _, query_song in dataset.iterrows():\n",
    "        # Define query\n",
    "        query_genre = query_song['genre'][0]  # Use the first genre as the primary genre\n",
    "        relevant_songs = dataset[dataset['genre'].apply(lambda genres: query_genre in genres)]['id'].tolist()\n",
    "        \n",
    "        # Random baseline\n",
    "        retrieved_songs = random_baseline(query_song, dataset, N=N)['id'].tolist()  # Use 'id' for metrics\n",
    "        \n",
    "        # Compute metrics\n",
    "        precision_list.append(precision_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        recall_list.append(recall_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        ndcg_list.append(ndcg_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        mrr_list.append(mean_reciprocal_rank(retrieved_songs, relevant_songs))\n",
    "    \n",
    "    # Compute averages\n",
    "    return {\n",
    "        \"Precision@10\": sum(precision_list) / len(precision_list),\n",
    "        \"Recall@10\": sum(recall_list) / len(recall_list),\n",
    "        \"NDCG@10\": sum(ndcg_list) / len(ndcg_list),\n",
    "        \"MRR\": sum(mrr_list) / len(mrr_list),\n",
    "    }\n",
    "\n",
    "# Run evaluation on the baseline system\n",
    "metrics = evaluate_baseline_with_info(dataset, N=10)\n",
    "\n",
    "# Display the results\n",
    "print(\"Evaluation Metrics for Random Baseline System:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lyrics_to_dataset(dataset, lyrics_file):\n",
    "    \"\"\"\n",
    "    Add lyrics to dataset and extract column values for text feature representation method.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "        dataset : pd.DataFrame\n",
    "            Pre-made dataset with song names, authors etc.\n",
    "        lyrics_file : str\n",
    "            Location of the file with precomputed lyrics features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple\n",
    "            Merged dataset, text feature representation method cols.\n",
    "    \"\"\"\n",
    "    lyrics_data = pd.read_csv(lyrics_file, sep='\\t')\n",
    "\n",
    "    # Ensuring column name consistency\n",
    "    dataset.columns = dataset.columns.str.strip()\n",
    "    lyrics_data.columns = lyrics_data.columns.str.strip()\n",
    "\n",
    "    # Excluding song col because it causes collision of the data and pandas processes it incorrectly\n",
    "    lyrics_data = lyrics_data.drop(columns=['song'])\n",
    "\n",
    "    merged_data = pd.merge(dataset, lyrics_data, on='id')\n",
    "\n",
    "    # Excluding id\n",
    "    feature_columns = lyrics_data.columns[1:]\n",
    "    return merged_data, feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_tf_idf_file = 'dataset/id_lyrics_tf-idf_mmsr.tsv'\n",
    "\n",
    "# Adding precomputed td-idf features to our dataset\n",
    "dataset_with_lyrics, tfidf_columns = add_lyrics_to_dataset(dataset, lyrics_tf_idf_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album_name</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>addict</th>\n",
       "      <th>...</th>\n",
       "      <th>yea</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01rMxQv6vhyE1oQX</td>\n",
       "      <td>[rock, pop punk]</td>\n",
       "      <td>Against the Current</td>\n",
       "      <td>Chasing Ghosts</td>\n",
       "      <td>In Our Bones</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02ZnlCGZEbkfCDxo</td>\n",
       "      <td>[pop, italian pop, latin, europop, ambient, po...</td>\n",
       "      <td>Laura Pausini</td>\n",
       "      <td>Tra Te E Il Mare</td>\n",
       "      <td>The Best of Laura Pausini - E Ritorno Da Te</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04OjszRi9rC5BlHC</td>\n",
       "      <td>[experimental, folk, lo fi, freak folk, indie ...</td>\n",
       "      <td>Grizzly Bear</td>\n",
       "      <td>Knife</td>\n",
       "      <td>Yellow House</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04iitW3ffa0mhpx3</td>\n",
       "      <td>[pop, r b, hip hop, soul, rhythm and blues, si...</td>\n",
       "      <td>Ne-Yo</td>\n",
       "      <td>Miss Independent</td>\n",
       "      <td>Year Of The Gentleman (Bonus Track Edition)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04xUDjAYC14jsHyH</td>\n",
       "      <td>[punk, emo, post hardcore, post punk, melodic ...</td>\n",
       "      <td>Jawbreaker</td>\n",
       "      <td>Jinx Removing</td>\n",
       "      <td>24 Hour Revenge Therapy (Remastered)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              genre  \\\n",
       "0  01rMxQv6vhyE1oQX                                   [rock, pop punk]   \n",
       "1  02ZnlCGZEbkfCDxo  [pop, italian pop, latin, europop, ambient, po...   \n",
       "2  04OjszRi9rC5BlHC  [experimental, folk, lo fi, freak folk, indie ...   \n",
       "3  04iitW3ffa0mhpx3  [pop, r b, hip hop, soul, rhythm and blues, si...   \n",
       "4  04xUDjAYC14jsHyH  [punk, emo, post hardcore, post punk, melodic ...   \n",
       "\n",
       "                artist              song  \\\n",
       "0  Against the Current    Chasing Ghosts   \n",
       "1        Laura Pausini  Tra Te E Il Mare   \n",
       "2         Grizzly Bear             Knife   \n",
       "3                Ne-Yo  Miss Independent   \n",
       "4           Jawbreaker     Jinx Removing   \n",
       "\n",
       "                                    album_name  abl  accept  across  act  \\\n",
       "0                                 In Our Bones  0.0     0.0     0.0  0.0   \n",
       "1  The Best of Laura Pausini - E Ritorno Da Te  0.0     0.0     0.0  0.0   \n",
       "2                                 Yellow House  0.0     0.0     0.0  0.0   \n",
       "3  Year Of The Gentleman (Bonus Track Edition)  0.0     0.0     0.0  0.0   \n",
       "4         24 Hour Revenge Therapy (Remastered)  0.0     0.0     0.0  0.0   \n",
       "\n",
       "   addict  ...  yea      yeah  year  yellow  yes  yesterday  yet   yo  young  \\\n",
       "0     0.0  ...  0.0  0.079754   0.0     0.0  0.0        0.0  0.0  0.0    0.0   \n",
       "1     0.0  ...  0.0  0.000000   0.0     0.0  0.0        0.0  0.0  0.0    0.0   \n",
       "2     0.0  ...  0.0  0.000000   0.0     0.0  0.0        0.0  0.0  0.0    0.0   \n",
       "3     0.0  ...  0.0  0.792131   0.0     0.0  0.0        0.0  0.0  0.0    0.0   \n",
       "4     0.0  ...  0.0  0.000000   0.0     0.0  0.0        0.0  0.0  0.0    0.0   \n",
       "\n",
       "   youth  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1004 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precomputed_embeddings_similarity(query_song, dataset, feature_columns, N=10):\n",
    "    \"\"\"\n",
    "    Compute similarity using precomputed text embedding vectors from the dataset.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "        query_song\n",
    "            The query song (row) from the dataset.\n",
    "        dataset\n",
    "            Full dataset containing precomputed features vectors.\n",
    "        feature_columns\n",
    "            List of columns corresponding to feature representation method features.\n",
    "        N\n",
    "            Number of top results to retrieve.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame\n",
    "            A DataFrame of the top N similar songs.\n",
    "    \"\"\"\n",
    "    # Extract the TF-IDF vector for the query song\n",
    "    query_vector = query_song[feature_columns].values.reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity with all songs\n",
    "    embed_matrix = dataset[feature_columns].values\n",
    "    similarities = cosine_similarity(query_vector, embed_matrix).flatten()\n",
    "\n",
    "    # Add similarity scores to dataset and exclude query song\n",
    "    dataset['similarity'] = similarities\n",
    "    results = dataset[dataset['id'] != query_song['id']].sort_values(by='similarity', ascending=False)\n",
    "\n",
    "    return results.head(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_precomputed_embeddings_retrieval(IR_system_name: str, dataset, feature_columns, N=10):\n",
    "    \"\"\"\n",
    "    Evaluate the text-based retrieval system using the same metrics.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "        IR_system_name\n",
    "            Name of the IR system, must be one of \"TF-IDF\", \"system2(TBD)\", or \"system3(TBD)\".\n",
    "        dataset\n",
    "            Full dataset containing genres and precomputed text embedding vectors.\n",
    "        feature_columns\n",
    "            List of columns corresponding to text embedding features.\n",
    "        N\n",
    "            Number of top results to retrieve for evaluation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        dict\n",
    "            A dictionary containing the evaluation metrics (Precision@10, Recall@10, etc.).\n",
    "    \"\"\"\n",
    "    if IR_system_name not in [\"TF-IDF\", \"system2(TBD)\", \"system3(TBD)\"]:\n",
    "        raise ValueError(\"IR_system_name must be one of 'TF-IDF', 'system2(TBD)', or 'system3(TBD)'\")\n",
    "\n",
    "    # Ensure the public directory exists\n",
    "    os.makedirs(\"public\", exist_ok=True)\n",
    "\n",
    "    # Create a hash based on input parameters\n",
    "    hash_input = IR_system_name + str(len(dataset)) + str(feature_columns) + str(N)\n",
    "    params_hash = hashlib.md5(hash_input.encode()).hexdigest()\n",
    "    filename = f\"{params_hash[:5]}.json\"\n",
    "    filepath = os.path.join(\"public\", filename)\n",
    "\n",
    "    # Check if the JSON cache file exists\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            cached_data = json.load(f)\n",
    "        # Extract metrics from cached file if present\n",
    "        metadata = cached_data.get(\"metadata\", {})\n",
    "        print(f\"The results are already cached. Metadata: {metadata}\")\n",
    "        return {\n",
    "            \"Precision@10\": metadata.get(\"Precision@10\", 0),\n",
    "            \"Recall@10\": metadata.get(\"Recall@10\", 0),\n",
    "            \"NDCG@10\": metadata.get(\"NDCG@10\", 0),\n",
    "            \"MRR\": metadata.get(\"MRR\", 0),\n",
    "        }\n",
    "\n",
    "    # No cache found, proceed with computation\n",
    "    precision_list, recall_list, ndcg_list, mrr_list = [], [], [], []\n",
    "    recommendations_dict = {}\n",
    "\n",
    "    for _, query_song in tqdm(dataset.iterrows(), total=len(dataset), desc=\"Evaluating retrieval\"):\n",
    "        query_genres = set(query_song['genre'])  # Convert query genres to a set\n",
    "        relevant_songs = dataset[dataset['genre'].apply(lambda genres: len(query_genres & set(genres)) > 0)]['id'].tolist()\n",
    "\n",
    "        retrieved_songs = compute_precomputed_embeddings_similarity(query_song, dataset, feature_columns, N=N)['id'].tolist()\n",
    "\n",
    "        # Store recommendations\n",
    "        recommendations_dict[query_song['id']] = retrieved_songs\n",
    "\n",
    "        # Compute metrics\n",
    "        precision_list.append(precision_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        recall_list.append(recall_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        ndcg_list.append(ndcg_at_k(retrieved_songs, relevant_songs, k=N))\n",
    "        mrr_list.append(mean_reciprocal_rank(retrieved_songs, relevant_songs))\n",
    "\n",
    "    # Compute averages\n",
    "    metrics = {\n",
    "        \"Precision@10\": sum(precision_list) / len(precision_list),\n",
    "        \"Recall@10\": sum(recall_list) / len(recall_list),\n",
    "        \"NDCG@10\": sum(ndcg_list) / len(ndcg_list),\n",
    "        \"MRR\": sum(mrr_list) / len(mrr_list),\n",
    "    }\n",
    "\n",
    "    # Save recommendations and metrics to JSON file\n",
    "    output_data = {\n",
    "        \"metadata\": {\n",
    "            \"IR_system_name\": IR_system_name,\n",
    "            \"N\": N,\n",
    "            \"feature_columns\": list(feature_columns),\n",
    "            \"Precision@10\": metrics[\"Precision@10\"],\n",
    "            \"Recall@10\": metrics[\"Recall@10\"],\n",
    "            \"NDCG@10\": metrics[\"NDCG@10\"],\n",
    "            \"MRR\": metrics[\"MRR\"]\n",
    "        },\n",
    "        \"content\": recommendations_dict\n",
    "    }\n",
    "\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval: 100%|██████████| 5148/5148 [06:01<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Retrieval Evaluation Metrics:\n",
      "Precision@10: 0.2066\n",
      "Recall@10: 0.0289\n",
      "NDCG@10: 0.5146\n",
      "MRR: 0.3663\n"
     ]
    }
   ],
   "source": [
    "# Use 10% of the dataset for faster execution\n",
    "# small_subset = dataset_with_lyrics.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Run evaluation\n",
    "tfidf_metrics = evaluate_precomputed_embeddings_retrieval(\"TF-IDF\", dataset_with_lyrics, tfidf_columns, N=100)\n",
    "\n",
    "# Display the results\n",
    "print(\"TF-IDF Retrieval Evaluation Metrics:\")\n",
    "for metric, value in tfidf_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_from_json(artist: str, song: str, filename: str, dataset):\n",
    "    # Load the cached JSON data\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Find the query song ID\n",
    "    query_id_series = dataset.loc[(dataset['artist'] == artist) & (dataset['song'] == song), 'id']\n",
    "    if query_id_series.empty:\n",
    "        raise ValueError(\"Song by the given artist not found in the dataset.\")\n",
    "    query_id = query_id_series.values[0]\n",
    "\n",
    "    # Retrieve recommended song IDs from JSON\n",
    "    recommended_ids = data['content'].get(query_id, [])\n",
    "    if not recommended_ids:\n",
    "        return f\"No recommendations found for {song} by {artist}.\"\n",
    "\n",
    "    # Return a dataframe of recommended songs and their artists\n",
    "    recommended_songs = dataset[dataset['id'].isin(recommended_ids)][['song', 'artist']]\n",
    "    return recommended_songs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebok UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20af81af00314d098555d7f0477caa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Combobox(value='', description='Artist:', options=('10,000 Maniacs', '2 Chainz', '2Pac', '3OH!3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = \"public/fb5d6.json\"  # Example filename from the previous run\n",
    "\n",
    "dataset = small_subset  # Use the small subset for the widget\n",
    "\n",
    "# Extract unique artists\n",
    "artists = sorted(dataset['artist'].unique())\n",
    "\n",
    "# Create artist selection widget with autocomplete\n",
    "artist_widget = Combobox(\n",
    "    placeholder='Type or select an artist',\n",
    "    options=artists,\n",
    "    description='Artist:'\n",
    ")\n",
    "\n",
    "# Create song selection widget with autocomplete\n",
    "song_widget = Combobox(\n",
    "    placeholder='Type or select a song',\n",
    "    options=[],\n",
    "    description='Song:'\n",
    ")\n",
    "\n",
    "# Update the song widget options based on the selected artist\n",
    "def update_songs(change):\n",
    "    if change['name'] == 'value' and change['new']:\n",
    "        selected_artist = change['new']\n",
    "        # Filter songs by the chosen artist\n",
    "        songs_by_artist = dataset[dataset['artist'] == selected_artist]['song'].unique()\n",
    "        song_widget.options = sorted(songs_by_artist) if len(songs_by_artist) > 0 else []\n",
    "\n",
    "artist_widget.observe(update_songs, 'value')\n",
    "\n",
    "# Button to get recommendations\n",
    "button = Button(description='Get Recommendations')\n",
    "output = Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if artist_widget.value and song_widget.value:\n",
    "            # Call the previously defined function\n",
    "            recommendations = get_recommendations_from_json(artist_widget.value, song_widget.value, filename, dataset)\n",
    "            display(recommendations)\n",
    "        else:\n",
    "            print(\"Please select both artist and song\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Arrange the widgets in a vertical box layout\n",
    "ui = VBox([artist_widget, song_widget, button, output])\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed. 'merged_dataset.tsv' created.\n"
     ]
    }
   ],
   "source": [
    "# List all your input TSV files\n",
    "files = [\n",
    "    \"dataset/id_genres_mmsr.tsv\",\n",
    "    \"dataset/id_metadata_mmsr.tsv\",\n",
    "    \"dataset/id_information_mmsr.tsv\",\n",
    "    \"dataset/id_url_mmsr.tsv\",\n",
    "    \"dataset/id_total_listens.tsv\"\n",
    "]\n",
    "\n",
    "# Read all the files into a list of DataFrames\n",
    "dataframes = [pd.read_csv(f, sep='\\t') for f in files]\n",
    "\n",
    "# Merge them all by 'id'\n",
    "merged_df = dataframes[0]\n",
    "for df in dataframes[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on='id', how='outer')\n",
    "\n",
    "# Write the merged data to a new TSV file\n",
    "merged_df.to_csv(\"public/data/merged_dataset.tsv\", sep='\\t', index=False)\n",
    "print(\"Merging completed. 'merged_dataset.tsv' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata by file written to ../public/data/precomputed_systems\\metadata_by_file.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing the JSON files\n",
    "input_dir = '../public/data/precomputed_systems'\n",
    "output_file = os.path.join(input_dir, 'metadata_by_file.json')\n",
    "\n",
    "# Function to read and extract metadata from a JSON file\n",
    "def extract_metadata(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        return data.get('metadata', {})\n",
    "\n",
    "# Dictionary to hold metadata with filenames as keys\n",
    "metadata_dict = {}\n",
    "\n",
    "# Iterate over all files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    if filename.endswith('.json') and file_path != output_file:\n",
    "        metadata = extract_metadata(file_path)\n",
    "        metadata_dict[filename] = metadata\n",
    "\n",
    "# Write metadata dictionary to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(metadata_dict, file, indent=2)\n",
    "\n",
    "print(f'Metadata by file written to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
